Il processo di fine tuning, noto anche come adattamento o addestramento aggiuntivo, è una fase cruciale nell'addestramento dei modelli di linguaggio quando si sa già che il task sarà molto specifico. Consiste nell'adattare un modello preaddestrato su un compito specifico o su un insieme di dati particolare. Questo processo consente al modello di acquisire conoscenze specifiche e dettagliate su un determinato dominio o compito senza dover addestrare il modello da zero.

Il processo ha molte fasi in comune con un training completo ma ha alcune differenze chiave. In particolare, il fine tuning richiede un insieme di dati di training più piccolo e un numero inferiore di epoche di addestramento. Questo perché il modello preaddestrato ha già acquisito una conoscenza generale del linguaggio e delle strutture grammaticali, che può essere riutilizzata per il compito specifico. Inoltre, il fine tuning richiede un'attenta regolazione degli iperparametri per evitare l'overfitting e garantire che il modello si adatti bene al compito specifico.

Il processo di fine tuning può essere suddiviso nelle seguenti fasi:
\begin{itemize}
    \item Preparazione dei dati: Prima di iniziare il processo di fine tuning, è necessario raccogliere e preparare un insieme di dati specifico per il compito di interesse. Questi dati dovrebbero essere etichettati correttamente per consentire al modello di apprendere la relazione tra gli input e le uscite desiderate.
    \item Caricamento del modello preaddestrato: Si parte da un modello preaddestrato, che è stato addestrato su un ampio corpus di testi generici. Questo modello ha già acquisito una conoscenza generale del linguaggio e delle strutture grammaticali.
    \item Aggiunta degli strati finali: Si aggiungono uno o più strati di rete neurale al modello preaddestrato. Questi strati aggiuntivi sono specifici per il compito in questione. Ad esempio, nel caso della classificazione di testi, gli strati finali potrebbero essere costituiti da un livello completamente connesso che trasforma l'output del modello in una previsione di classe.
    \item Inizializzazione dei pesi: Gli strati aggiuntivi vengono inizializzati casualmente o utilizzando pesi provenienti dal modello preaddestrato. Questo passaggio è importante perché consente di iniziare l'addestramento con una base già buona acquisita durante il preaddestramento.
    \item Addestramento: Si addestra il modello sui dati del compito specifico utilizzando l'ottimizzazione del gradiente stocastico (SGD) o altri algoritmi di ottimizzazione. Durante l'addestramento, il modello aggiusta i pesi degli strati aggiuntivi per adattarsi ai dati del compito, cercando di minimizzare la perdita tra le previsioni del modello e le etichette di training.
    \item Validazione e tuning degli iperparametri: Si monitora il modello durante l'addestramento utilizzando un insieme di dati di validazione separato. Questo permette di valutare le prestazioni del modello su dati non visti e di regolare gli iperparametri, come il tasso di apprendimento o le dimensioni del batch, per migliorare le prestazioni.
    \item Controllo dell'overfitting: Come nell'addestramento di modelli di deep learning, è importante prevenire l'overfitting durante il fine tuning. Questo può essere fatto utilizzando tecniche di regolarizzazione come l'eliminazione casuale, la riduzione del tasso di apprendimento e l'uso di dati di validazione.
    \item Test finale: Dopo che il modello ha raggiunto una buona performance sui dati di validazione, viene testato su un insieme di dati di test separato, che non è stato utilizzato né per il preaddestramento né per il fine tuning. Questo test fornisce una stima delle prestazioni del modello su dati completamente nuovi.
    \item Deployment: Una volta che il modello ha superato con successo il test finale, può essere deployato per l'uso nel mondo reale. Può essere integrato in applicazioni, sistemi automatizzati o piattaforme che richiedono il compito specifico che il modello è stato addestrato a svolgere.
    
\end{itemize}
In sintesi, il fine tuning è un passaggio essenziale per adattare un modello preaddestrato a compiti specifici. Consente di sfruttare la conoscenza generale del linguaggio acquisita durante il preaddestramento e di personalizzare il modello per affrontare compiti più specializzati o dominii specifici.

Ci sono altre tecniche con il quale si può far "apprendere" al modello di linguaggio un task, per esempio si può utilizzare una tecnica definita "few-shot" ovvero gli si inserisce nell'input al modello una spiegazione breve e con qualche esempio di ciò che deve fare e si lascia ragionare il modello con le sue capacità, senza fare passaggi di allenamento di nessun tipo. Le tenciche come il few-shot o lo 0-shot (in cui gli si spiega solo il compito) funzionano egregiamente con modelli molto grandi e complessi ma quando il task inizia ad essere più complesso di un semplice "traduci da inglese a italiano" o "traduci da italiano a inglese" allora si inizia a perdere qualità e precisione. Questo è dovuto al fatto che il modello non ha una conoscenza di base del linguaggio e quindi non può fare ragionamenti complessi. Questo è il motivo per cui si utilizza il fine tuning, per dare al modello una conoscenza di base del linguaggio e poi farlo ragionare su un task specifico.