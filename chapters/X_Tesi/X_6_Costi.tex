I costi di un sistema di information retrieval basato su LLM possono essere divisi in due tipologie: fissi e di utilizzo.

I costi fissi sono quelli che non dipendono dal numero di query effettuate, ma solo dal numero di documenti indicizzati e dalla loro lunghezza.

Per il lavoro di tesi sono state utilizzate le API di OpenAI per semplicità di utilizzo e anche perché non richiedono capacità computazionali in loco.

Le api di OpenAI inoltre hanno un diverso costo rispetto al modello utilizzato. 

Il costo di indicizzazione utilizzando i modelli di OpenAI è di:

\begin{center}
    \begin{tabular}{|c|c|}
        \hline
        Model	& Usage \\
        \hline
        Ada v2	& \$0.0001\/1000 tokens \\
        \hline
    \end{tabular}
\end{center}

OpenAI stessa mette a disposizione altri modelli di embeddings ma ne sconsiglia l'utilizzo.

Il costo totale dell'indicizzazione è stato intorno ai 60\$.

Per quanto riguarda invece il costo di utilizzo, OpenAI mette a disposizione diversi modelli con diversi costi descritti nella tabella seguente:

\begin{center}
    \begin{tabular}{|c|c|c|c|}
        \hline
        Family & Model	& Input cost & Output cost \\
        \hline
        GPT-4 & 8k context	& \$0.03 / 1000 tokens &  	\$0.06 / 1000 tokens \\
        \hline
        & 32k context	& \$0.06 / 1000 tokens &  	\$0.12 / 1000 tokens \\
        \hline
        GPT-3.5 Turbo & 4k context	& \$0.0015 / 1000 tokens &  	\$0.002 / 1000 tokens \\
        \hline
        & 16k context	& \$0.003 / 1000 tokens &  	\$0.004 / 1000 tokens \\
        \hline

        GPT-3 & davinci	& \$0.0120 \/ 1000 tokens &  	\$0.0120  \/ 1000 tokens \\
        \hline
    \end{tabular}
\end{center}



Se si fosse utilizzato un modello di LLM proprietario o di terze parti in modo diretto sarebbe stato necessario un server con una GPU per poter effettuare le query in modo efficiente. In tal caso i costi si sarebbero ammortizzati sul lungo periodo.


